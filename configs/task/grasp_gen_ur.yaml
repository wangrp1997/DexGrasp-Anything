name: grasp_gen_ur
lr: 1e-4
eval_interval: 1
eval_visualize: 1

train:
  batch_size: 128
  num_workers: 0
  num_epochs: 3000
  log_step: 100

test:
  epoch: null
  batch_size: 32
  num_workers: 0

dataset:
  use_llm: ${llm.enabled}
  name: ${dataset.active}  # Reference global configuration
  desc: '[${dataset.active} ShadowHand] -- dataset used for grasp pose generation'
  normalize_x: true
  normalize_x_trans: true
  modeling_keys: ['allDoFs']
  num_points: 2048
  frame_interval_train: 5
  frame_interval_test: 10
  device: cuda
  use_color: false
  use_normal: true
  is_downsample: true
  train_transforms: ['NumpyToTensor']
  test_transforms: ['NumpyToTensor']
  transform_cfg: {}
  asset_dir: ${dataset.paths.${dataset.active}.asset_dir}
  asset_dir_slurm: ${dataset.paths.${dataset.active}.asset_dir_slurm}

visualizer:
  name: GraspGenURVisualizer
  ksample: ${task.test.batch_size} # sample k case in each case
  vis_denoising: false # visualize denoising process
  visualize: false
  visualize_html: false
  interval: 1
  use_llm: ${llm.enabled}
